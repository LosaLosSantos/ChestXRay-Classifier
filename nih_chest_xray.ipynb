{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as pli\n",
        "import seaborn as sns\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_colab_memory(path):\n",
        "    !rm -r {path}\n",
        "\n",
        "def save_to_drive(src, dest):\n",
        "    !cp -r {src} {dest}\n",
        "\n",
        "# Esempio di utilizzo\n",
        "# clean_colab_memory('/content/nih_chest_xray_subset')\n",
        "# save_to_drive('/content/nih_chest_xray_subset', '/content/drive/My Drive/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "labels_path = \"/content/drive/MyDrive/nih_chest_xray_subset/sample_labels.csv\"\n",
        "labels_df = pd.read_csv(labels_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5606 entries, 0 to 5605\n",
            "Data columns (total 11 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Image Index                  5606 non-null   object \n",
            " 1   Finding Labels               5606 non-null   object \n",
            " 2   Follow-up #                  5606 non-null   int64  \n",
            " 3   Patient ID                   5606 non-null   int64  \n",
            " 4   Patient Age                  5606 non-null   object \n",
            " 5   Patient Gender               5606 non-null   object \n",
            " 6   View Position                5606 non-null   object \n",
            " 7   OriginalImageWidth           5606 non-null   int64  \n",
            " 8   OriginalImageHeight          5606 non-null   int64  \n",
            " 9   OriginalImagePixelSpacing_x  5606 non-null   float64\n",
            " 10  OriginalImagePixelSpacing_y  5606 non-null   float64\n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 481.9+ KB\n"
          ]
        }
      ],
      "source": [
        "labels_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"labels_df\",\n  \"rows\": 5606,\n  \"fields\": [\n    {\n      \"column\": \"Image Index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5606,\n        \"samples\": [\n          \"00011065_007.png\",\n          \"00009892_001.png\",\n          \"00001836_076.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Finding Labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 244,\n        \"samples\": [\n          \"Fibrosis|Pleural_Thickening\",\n          \"Effusion\",\n          \"Consolidation|Effusion|Infiltration|Pleural_Thickening\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Follow-up #\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 177,\n        \"num_unique_values\": 113,\n        \"samples\": [\n          75,\n          2,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Patient ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8411,\n        \"min\": 13,\n        \"max\": 30797,\n        \"num_unique_values\": 4230,\n        \"samples\": [\n          11832,\n          22684,\n          18261\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Patient Age\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 92,\n        \"samples\": [\n          \"037Y\",\n          \"069Y\",\n          \"026Y\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Patient Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"F\",\n          \"M\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"View Position\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"PA\",\n          \"AP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OriginalImageWidth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 347,\n        \"min\": 1362,\n        \"max\": 3266,\n        \"num_unique_values\": 362,\n        \"samples\": [\n          2442,\n          2434\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OriginalImageHeight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 399,\n        \"min\": 966,\n        \"max\": 3056,\n        \"num_unique_values\": 341,\n        \"samples\": [\n          1844,\n          2437\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OriginalImagePixelSpacing_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016201412651388684,\n        \"min\": 0.115,\n        \"max\": 0.1988,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.115,\n          0.168\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OriginalImagePixelSpacing_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016201412651388684,\n        \"min\": 0.115,\n        \"max\": 0.1988,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.115,\n          0.168\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "labels_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e63da771-b2a7-4a77-b2f9-f2f17cb650ee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>Finding Labels</th>\n",
              "      <th>Follow-up #</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Patient Age</th>\n",
              "      <th>Patient Gender</th>\n",
              "      <th>View Position</th>\n",
              "      <th>OriginalImageWidth</th>\n",
              "      <th>OriginalImageHeight</th>\n",
              "      <th>OriginalImagePixelSpacing_x</th>\n",
              "      <th>OriginalImagePixelSpacing_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000013_005.png</td>\n",
              "      <td>Emphysema|Infiltration|Pleural_Thickening|Pneu...</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>060Y</td>\n",
              "      <td>M</td>\n",
              "      <td>AP</td>\n",
              "      <td>3056</td>\n",
              "      <td>2544</td>\n",
              "      <td>0.139</td>\n",
              "      <td>0.139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00000013_026.png</td>\n",
              "      <td>Cardiomegaly|Emphysema</td>\n",
              "      <td>26</td>\n",
              "      <td>13</td>\n",
              "      <td>057Y</td>\n",
              "      <td>M</td>\n",
              "      <td>AP</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00000017_001.png</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>077Y</td>\n",
              "      <td>M</td>\n",
              "      <td>AP</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00000030_001.png</td>\n",
              "      <td>Atelectasis</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>079Y</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2992</td>\n",
              "      <td>2991</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00000032_001.png</td>\n",
              "      <td>Cardiomegaly|Edema|Effusion</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>055Y</td>\n",
              "      <td>F</td>\n",
              "      <td>AP</td>\n",
              "      <td>2500</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0.168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e63da771-b2a7-4a77-b2f9-f2f17cb650ee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e63da771-b2a7-4a77-b2f9-f2f17cb650ee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e63da771-b2a7-4a77-b2f9-f2f17cb650ee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a75442a6-0f81-4faf-9393-00ac97700ad1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a75442a6-0f81-4faf-9393-00ac97700ad1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a75442a6-0f81-4faf-9393-00ac97700ad1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        Image Index                                     Finding Labels  \\\n",
              "0  00000013_005.png  Emphysema|Infiltration|Pleural_Thickening|Pneu...   \n",
              "1  00000013_026.png                             Cardiomegaly|Emphysema   \n",
              "2  00000017_001.png                                         No Finding   \n",
              "3  00000030_001.png                                        Atelectasis   \n",
              "4  00000032_001.png                        Cardiomegaly|Edema|Effusion   \n",
              "\n",
              "   Follow-up #  Patient ID Patient Age Patient Gender View Position  \\\n",
              "0            5          13        060Y              M            AP   \n",
              "1           26          13        057Y              M            AP   \n",
              "2            1          17        077Y              M            AP   \n",
              "3            1          30        079Y              M            PA   \n",
              "4            1          32        055Y              F            AP   \n",
              "\n",
              "   OriginalImageWidth  OriginalImageHeight  OriginalImagePixelSpacing_x  \\\n",
              "0                3056                 2544                        0.139   \n",
              "1                2500                 2048                        0.168   \n",
              "2                2500                 2048                        0.168   \n",
              "3                2992                 2991                        0.143   \n",
              "4                2500                 2048                        0.168   \n",
              "\n",
              "   OriginalImagePixelSpacing_y  \n",
              "0                        0.139  \n",
              "1                        0.168  \n",
              "2                        0.168  \n",
              "3                        0.143  \n",
              "4                        0.168  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "labels_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5606, 11)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "labels_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Finding Labels</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>No Finding</th>\n",
              "      <td>3044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Infiltration</th>\n",
              "      <td>503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Effusion</th>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Atelectasis</th>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nodule</th>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Atelectasis|Edema|Effusion|Infiltration|Pneumonia</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Atelectasis|Consolidation|Edema|Infiltration|Pneumonia</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Atelectasis|Effusion|Hernia</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Atelectasis|Hernia|Pneumothorax</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cardiomegaly|Effusion|Emphysema</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>244 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "Finding Labels\n",
              "No Finding                                                3044\n",
              "Infiltration                                               503\n",
              "Effusion                                                   203\n",
              "Atelectasis                                                192\n",
              "Nodule                                                     144\n",
              "                                                          ... \n",
              "Atelectasis|Edema|Effusion|Infiltration|Pneumonia            1\n",
              "Atelectasis|Consolidation|Edema|Infiltration|Pneumonia       1\n",
              "Atelectasis|Effusion|Hernia                                  1\n",
              "Atelectasis|Hernia|Pneumothorax                              1\n",
              "Cardiomegaly|Effusion|Emphysema                              1\n",
              "Name: count, Length: 244, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "labels_df['Finding Labels'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'image_path': '/content/drive/MyDrive/nih_chest_xray_subset/images/00000013_005.png', 'labels': ['Emphysema', 'Infiltration', 'Pleural_Thickening', 'Pneumothorax']}, {'image_path': '/content/drive/MyDrive/nih_chest_xray_subset/images/00000013_026.png', 'labels': ['Cardiomegaly', 'Emphysema']}, {'image_path': '/content/drive/MyDrive/nih_chest_xray_subset/images/00000017_001.png', 'labels': ['No Finding']}, {'image_path': '/content/drive/MyDrive/nih_chest_xray_subset/images/00000030_001.png', 'labels': ['Atelectasis']}, {'image_path': '/content/drive/MyDrive/nih_chest_xray_subset/images/00000032_001.png', 'labels': ['Cardiomegaly', 'Edema', 'Effusion']}]\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "\n",
        "for _, row in labels_df.iterrows():\n",
        "    image_path = os.path.join('/content/drive/MyDrive/nih_chest_xray_subset/images', row['Image Index'])\n",
        "    labels = row['Finding Labels'].split('|')\n",
        "    data.append({'image_path': image_path, 'labels': labels})\n",
        "\n",
        "print(data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "967\n"
          ]
        }
      ],
      "source": [
        "num_class_1 = sum([\"Infiltration\" in r[\"labels\"] for r in data])\n",
        "print(num_class_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4639\n"
          ]
        }
      ],
      "source": [
        "num_class_0 = sum([\"Infiltration\" not in r[\"labels\"] for r in data])\n",
        "print(num_class_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esempi della classe 1 disponibili per augmentation: 967\n"
          ]
        }
      ],
      "source": [
        "class_1_data = [r for r in data if \"Infiltration\" in r[\"labels\"]]\n",
        "\n",
        "print(f\"Esempi della classe 1 disponibili per augmentation: {len(class_1_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_item(image_path, label):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224]) / 255.0\n",
        "    return image, label\n",
        "\n",
        "paths = [item['image_path'] for item in data]\n",
        "labels = [1 if \"Infiltration\" in item[\"labels\"] else 0 for item in data]\n",
        "\n",
        "# Preprocessing con parallelismo\n",
        "dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "dataset = dataset.map(lambda x, y: preprocess_item(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset_nobatch = dataset\n",
        "# Shuffle per migliorare il training\n",
        "dataset = dataset.shuffle(buffer_size=1000)  # Cambia il buffer in base al dataset\n",
        "\n",
        "# Creazione dei batch # Prefetch per caricare il batch successivo in parallelo\n",
        "dataset = dataset.batch(64).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch shape: (64, 224, 224, 3), Labels shape: (64,)\n"
          ]
        }
      ],
      "source": [
        "for images, labels in dataset.take(1):\n",
        "    print(f\"Batch shape: {images.shape}, Labels shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loaded_dataset = tf.data.Dataset.load(\"/content/drive/MyDrive/nih_chest_xray_subset/processed_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#total_images = 0\n",
        "#for images, labels in dataset:\n",
        "#   total_images += images.shape[0]\n",
        "#\n",
        "#print(f\"Total_number_of: {total_images}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tf.data.experimental.save(dataset,\"/content/drive/MyDrive/nih_chest_xray_subset/processed_dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TensorFlow Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False # don't update base_model weights during training\n",
        "\n",
        "model = tf.keras.Sequential([base_model, tf.keras.layers.GlobalAveragePooling2D(), tf.keras.layers.Dense(1, activation='sigmoid')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),loss='binary_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_size = len(dataset)\n",
        "\n",
        "test_size = int(dataset_size * 0.2)\n",
        "validation_size = int(dataset_size * 0.1)\n",
        "train_size = dataset_size - test_size - validation_size\n",
        "\n",
        "test_set = dataset.take(test_size)  # Primi 20% per il test\n",
        "validation_set = dataset.skip(test_size).take(validation_size)  # Successivi 20% per validazione\n",
        "train_set = dataset.skip(test_size + validation_size)  # Resto per il training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset totale (batch): 88\n",
            "Test set (batch): 17\n",
            "Validation set (batch): 8\n",
            "Training set (batch): 63\n"
          ]
        }
      ],
      "source": [
        "print(f\"Dataset totale (batch): {dataset_size}\")\n",
        "print(f\"Test set (batch): {test_size}\")\n",
        "print(f\"Validation set (batch): {validation_size}\")\n",
        "print(f\"Training set (batch): {train_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 4s/step - accuracy: 0.8224 - loss: 0.4541 - val_accuracy: 0.8652 - val_loss: 0.3916\n",
            "Epoch 2/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 3s/step - accuracy: 0.8204 - loss: 0.4506 - val_accuracy: 0.8633 - val_loss: 0.3935\n",
            "Epoch 3/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 3s/step - accuracy: 0.8315 - loss: 0.4330 - val_accuracy: 0.8672 - val_loss: 0.3661\n",
            "Epoch 4/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - accuracy: 0.8296 - loss: 0.4249 - val_accuracy: 0.8496 - val_loss: 0.4157\n",
            "Epoch 5/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 4s/step - accuracy: 0.8215 - loss: 0.4439 - val_accuracy: 0.8477 - val_loss: 0.4217\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_set, epochs=5, validation_data = validation_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.8676 - loss: 0.3951\n",
            "Test Loss: 0.4276522397994995, Test Accuracy: 0.8428308963775635\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_set)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.99      0.92       932\n",
            "           1       0.53      0.05      0.09       156\n",
            "\n",
            "    accuracy                           0.86      1088\n",
            "   macro avg       0.70      0.52      0.51      1088\n",
            "weighted avg       0.81      0.86      0.80      1088\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_true = []  # Ground truth\n",
        "y_pred = []  # Predizioni\n",
        "for images, labels in test_set:\n",
        "    preds = model.predict(images)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend((preds > 0.5).astype(int).flatten())\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is due to the imbalance of the dataset:  \n",
        "the model almost always predicts 0, largely ignoring class 1.  \n",
        "On class 1 we experienced:  \n",
        "Precision = 50%: The model makes few predictions like 1, but half of these predictions are correct.  \n",
        "Recall = 2%: The model identifies only 2% of the real class 1 examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CovNet(nn.Module):\n",
        "  def __init__(self, channels, classes):\n",
        "    super(CovNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=32, kernel_size=(5,5), padding='same')\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(5,5), padding='same')\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.maxpool2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=64*56*56, out_features=128)\n",
        "    self.relu3 = nn.ReLU()\n",
        "\n",
        "    self.fc2 = nn.Linear(in_features=128, out_features=classes)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward_pass(self, x):\n",
        "    x = nn.functional.relu(self.conv1(x))\n",
        "    x = self.maxpool1(x)\n",
        "    x = nn.functional.relu(self.conv2(x))\n",
        "    x = self.maxpool2\n",
        "    x = self.flatten(x)\n",
        "    x = nn.functional.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    x = self.softmax(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = CovNet(input,channels=3, classes=num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = #Dataset\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = #Dataset\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = {'train_loss': [],\n",
        "    'train_acc': [],\n",
        "    'test_loss': [],\n",
        "    'test_acc': []}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "    for batch_size, (data, targets) in enumerate(tqdm(train_dataset)):\n",
        "\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        scores = model(data)\n",
        "        loss = loss(scores, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATA AUGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esempi da augmentare: 3672\n",
            "967\n",
            "3672 5606\n",
            "58 88\n"
          ]
        }
      ],
      "source": [
        "# Filtra solo immagini di classe 1\n",
        "class_1_data = [item for item in data if \"Infiltration\" in item[\"labels\"]]\n",
        "class_1_paths = [item['image_path'] for item in class_1_data]\n",
        "class_1_labels = [1] * len(class_1_data)\n",
        "\n",
        "class_1_dataset = tf.data.Dataset.from_tensor_slices((class_1_paths, class_1_labels))\n",
        "\n",
        "def augment_image(image):\n",
        "    # Operazioni di augmentazione\n",
        "    image = tf.image.random_flip_left_right(image)  # Flip orizzontale\n",
        "    image = tf.image.random_flip_up_down(image)    # Flip verticale\n",
        "    image = tf.image.rot90(image, k=np.random.randint(1, 4))  # Rotazione casuale\n",
        "    return image\n",
        "\n",
        "# Applica augmentation agli esempi di classe 1\n",
        "def preprocess_and_augment(image_path, label):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224]) / 255.0\n",
        "    image = augment_image(image)  # Applica augmentation\n",
        "    return image, label\n",
        "\n",
        "# Conta gli esempi di classe 0\n",
        "num_class_0 = sum(1 for item in data if \"Infiltration\" not in item[\"labels\"])\n",
        "# Conta gli esempi di classe 1\n",
        "num_class_1 = len(class_1_paths)\n",
        "# Numero di esempi da generare per bilanciare\n",
        "num_to_augment = num_class_0 - num_class_1\n",
        "print(f\"Esempi da augmentare: {num_to_augment}\")\n",
        "\n",
        "# Dataset augmentato per la classe 1\n",
        "augmented_class_1_dataset = class_1_dataset.map(preprocess_and_augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "print(len(augmented_class_1_dataset))\n",
        "augmented_class_1_dataset = augmented_class_1_dataset.repeat().take(num_to_augment)\n",
        "# Ripeti per bilanciare\n",
        "augmented_class_1_dataset_nobatch = augmented_class_1_dataset\n",
        "print(len(augmented_class_1_dataset_nobatch), len(dataset_nobatch))\n",
        "augmented_class_1_dataset = augmented_class_1_dataset.batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "print(len(augmented_class_1_dataset), len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_samples(dataset):\n",
        "    count = 0\n",
        "    for _ in dataset:\n",
        "        count += 1\n",
        "    return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numero totale di campioni: 9278, Numero totale atteso: 9278\n"
          ]
        }
      ],
      "source": [
        "# Combina dataset originale e augmentato\n",
        "balanced_dataset = dataset_nobatch.concatenate(augmented_class_1_dataset_nobatch)\n",
        "# Conta il numero totale di campioni\n",
        "total_samples = count_samples(balanced_dataset)\n",
        "print(f\"Numero totale di campioni: {total_samples}, Numero totale atteso: {num_class_1 + num_class_0 + num_to_augment}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuzione delle classi nel dataset bilanciato: {'class_0': 4639, 'class_1': 4639}\n"
          ]
        }
      ],
      "source": [
        "class_counts = {\"class_0\": 0, \"class_1\": 0}\n",
        "\n",
        "for _, label in balanced_dataset:\n",
        "    if label.numpy() == 0:\n",
        "        class_counts[\"class_0\"] += 1\n",
        "    else:\n",
        "        class_counts[\"class_1\"] += 1\n",
        "\n",
        "print(f\"Distribuzione delle classi nel dataset bilanciato: {class_counts}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "balanced_dataset = balanced_dataset.shuffle(buffer_size=1000)\n",
        "balanced_dataset = balanced_dataset.batch(64).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TensorFlow Keras  \n",
        "#### (with new dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_size = len(balanced_dataset)\n",
        "test_size = int(dataset_size * 0.2)\n",
        "validation_size = int(dataset_size * 0.1)\n",
        "train_size = dataset_size - test_size - validation_size\n",
        "\n",
        "test_set = balanced_dataset.take(test_size)  # Primi 20% per il test\n",
        "validation_set = balanced_dataset.skip(test_size).take(validation_size)  # Successivi 20% per validazione\n",
        "train_set = balanced_dataset.skip(test_size + validation_size)  # Resto per il training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset totale: 145\n",
            "Test set: 29\n",
            "Validation set: 14\n",
            "Training set: 102\n"
          ]
        }
      ],
      "source": [
        "print(f\"Dataset totale: {dataset_size}\")\n",
        "print(f\"Test set: {test_size}\")\n",
        "print(f\"Validation set: {validation_size}\")\n",
        "print(f\"Training set: {train_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 4s/step - accuracy: 0.7982 - loss: 0.4501 - val_accuracy: 0.1585 - val_loss: 2.9227\n",
            "Epoch 2/5\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 4s/step - accuracy: 0.6894 - loss: 0.8967 - val_accuracy: 0.1540 - val_loss: 2.6816\n",
            "Epoch 3/5\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 4s/step - accuracy: 0.6891 - loss: 0.8501 - val_accuracy: 0.1518 - val_loss: 2.6926\n",
            "Epoch 4/5\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 4s/step - accuracy: 0.6837 - loss: 0.8549 - val_accuracy: 0.1618 - val_loss: 2.8316\n",
            "Epoch 5/5\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 4s/step - accuracy: 0.6817 - loss: 0.8980 - val_accuracy: 0.1607 - val_loss: 2.5189\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_set, epochs=5, validation_data=validation_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 3s/step - accuracy: 0.1441 - loss: 2.5362\n",
            "Test Loss: 2.5373177528381348, Test Accuracy: 0.14709052443504333\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_set)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1615\n",
            "           1       0.13      1.00      0.23       241\n",
            "\n",
            "    accuracy                           0.13      1856\n",
            "   macro avg       0.06      0.50      0.11      1856\n",
            "weighted avg       0.02      0.13      0.03      1856\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "y_true = []  # Ground truth\n",
        "y_pred = []  # Predizioni\n",
        "for images, labels in test_set:\n",
        "    preds = model.predict(images)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend((preds > 0.5).astype(int).flatten())\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
